{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af1a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import Normalize, to_rgb\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from skimage import measure, color\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1004a047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf4f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "number_raster_layers = 9\n",
    "number_pixels_layer = 19\n",
    "\n",
    "class CNNRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNRegressor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(number_raster_layers, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.selu1 = nn.SELU()\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.selu2 = nn.SELU()\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.selu3 = nn.SELU()\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.selu4 = nn.SELU()\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.selu5 = nn.SELU()\n",
    "        self.conv6 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.selu6 = nn.SELU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(512 * number_pixels_layer * number_pixels_layer, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.selu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.selu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.selu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.selu4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.selu5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.selu6(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = CNNRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4872bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "path_model = '../../Data/Calibrated_models/global_regressor_V0.pth'\n",
    "model.load_state_dict(torch.load(path_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1cfeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambia el modelo al modo de evaluaciÃ³n (si es necesario)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12456b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tensors\n",
    "path_tensor_train = '../../Data/Calibrated_models/global_regressor_V0_tensor_y_train.pth'\n",
    "y_train = torch.load(path_tensor_train)\n",
    "\n",
    "path_tensor_test = '../../Data/Calibrated_models/global_regressor_V0_tensor_y_test.pth'\n",
    "y_test = torch.load(path_tensor_test)\n",
    "\n",
    "path_tensor_test = '../../Data/Calibrated_models/global_regressor_V0_test_tensor.pth'\n",
    "test_tensor = torch.load(path_tensor_test)\n",
    "\n",
    "path_tensor_training = '../../Data/Calibrated_models/global_regressor_V0_training_tensor.pth'\n",
    "training_tensor = torch.load(path_tensor_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849a50d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# DataFrame to store all the results for pixel importance\n",
    "result_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7f361e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773972d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all elements of the first dimension of test_tensor\n",
    "for input_tensor_number in range(test_tensor.shape[0]):\n",
    "   \n",
    "    print(input_tensor_number)\n",
    "\n",
    "    input_tensor_raw = test_tensor[input_tensor_number].unsqueeze(0)  # Step 9\n",
    "\n",
    "    # Convert the input tensor to float to manipulate it with the CNN\n",
    "    input_tensor = input_tensor_raw.float()\n",
    "    \n",
    "    input_tensor_squeeze = input_tensor.squeeze(0)\n",
    "\n",
    "    # Define the color palette according to land cover types\n",
    "    color_map = {\n",
    "        0: 'saddlebrown',   # Bare\n",
    "        1: 'red',           # BuiltUp\n",
    "        2: 'yellow',        # Crops\n",
    "        3: 'lightgreen',    # Grass\n",
    "        4: 'limegreen',     # MossLichen\n",
    "        5: 'blue',          # PermanentWater\n",
    "        6: 'cyan',          # SeasonalWater\n",
    "        7: 'olive',         # Shrub\n",
    "        8: 'darkgreen'      # Tree\n",
    "    }\n",
    "\n",
    "    # Determine the dominant layer for each pixel\n",
    "    dominant_layer_indices = np.argmax(input_tensor_squeeze, axis=0)\n",
    "\n",
    "    # Create an empty RGB image\n",
    "    dominant_image = np.zeros((*dominant_layer_indices.shape, 3), dtype=np.uint8)\n",
    "\n",
    "    # Map each index to its corresponding color in the RGB image\n",
    "    for index, color in color_map.items():\n",
    "        mask = dominant_layer_indices == index\n",
    "        dominant_image[mask] = np.array(to_rgb(color)) * 255  # Convert color to RGB and adjust to scale 0-255\n",
    "\n",
    "    # Define the color palette according to land cover types\n",
    "    color_map = {\n",
    "        0: 'saddlebrown',   # Bare\n",
    "        1: 'red',           # BuiltUp\n",
    "        2: 'yellow',        # Crops\n",
    "        3: 'lightgreen',    # Grass\n",
    "        4: 'limegreen',     # MossLichen\n",
    "        5: 'blue',          # PermanentWater\n",
    "        6: 'cyan',          # SeasonalWater\n",
    "        7: 'olive',         # Shrub\n",
    "        8: 'darkgreen'      # Tree\n",
    "    }\n",
    "\n",
    "    # Labels for the legend based on category names\n",
    "    labels = {\n",
    "        0: \"Bare\",\n",
    "        1: \"Built-Up\",\n",
    "        2: \"Crops\",\n",
    "        3: \"Grass\",\n",
    "        4: \"Moss/Lichen\",\n",
    "        5: \"Permanent Water\",\n",
    "        6: \"Seasonal Water\",\n",
    "        7: \"Shrub\",\n",
    "        8: \"Tree\"\n",
    "    }\n",
    "\n",
    "    # Plot image (sanity check)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.imshow(dominant_image)\n",
    "    ax.axis('on')\n",
    "\n",
    "    # Create a list of patches for the legend\n",
    "    patches = [mpatches.Patch(color=to_rgb(color), label=labels[idx]) for idx, color in color_map.items()]\n",
    "\n",
    "    # Add the legend to the plot\n",
    "    plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    ax.xaxis.set_ticks([]) \n",
    "    ax.yaxis.set_ticks([]) \n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    ##################################################\n",
    "    # CREATE GRAD-CAM HEATMAP\n",
    "    ##################################################\n",
    "    \n",
    "    class GradCAM:\n",
    "        def __init__(self, model, layer):\n",
    "            self.model = model\n",
    "            self.layer = layer\n",
    "            self.gradient = None\n",
    "            self.activation = None\n",
    "\n",
    "            self.hook_handles = []\n",
    "            self.hook_handles.append(layer.register_forward_hook(self.save_activation))\n",
    "            self.hook_handles.append(layer.register_backward_hook(self.save_gradient))\n",
    "\n",
    "        def save_activation(self, module, input, output):\n",
    "            self.activation = output.detach()\n",
    "\n",
    "        def save_gradient(self, module, grad_input, grad_output):\n",
    "            self.gradient = grad_output[0].detach()\n",
    "\n",
    "        def __call__(self, x, index=None):\n",
    "            # Set a fixed seed for reproducibility\n",
    "            if seed is not None:\n",
    "                torch.manual_seed(seed)\n",
    "                torch.cuda.manual_seed_all(seed)\n",
    "                np.random.seed(seed)\n",
    "                random.seed(seed)\n",
    "\n",
    "            # Clear previous gradients and activations\n",
    "            self.gradient = None\n",
    "            self.activation = None\n",
    "\n",
    "            output = self.model(x)\n",
    "            if index is None:\n",
    "                index = torch.argmax(output)\n",
    "\n",
    "            self.model.zero_grad()\n",
    "            output.backward(torch.ones_like(output), retain_graph=True)\n",
    "\n",
    "            pooled_gradients = torch.mean(self.gradient, dim=[0, 2, 3])\n",
    "            for i in range(pooled_gradients.size(0)):\n",
    "                self.activation[:, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "            heatmap = torch.mean(self.activation, dim=1).squeeze()\n",
    "            heatmap = F.relu(heatmap)\n",
    "            heatmap /= torch.max(heatmap)\n",
    "\n",
    "            return heatmap\n",
    "\n",
    "        def release(self):\n",
    "            for handle in self.hook_handles:\n",
    "                handle.remove()\n",
    "\n",
    "    ###############################################################\n",
    "    ###############################################################\n",
    "\n",
    "    # Use GradCAM on the model with the conv6 layer\n",
    "    grad_cam = GradCAM(model, model.conv6)\n",
    "    # Set a fixed seed to ensure reproducibility\n",
    "    seed = 42\n",
    "    # Obtain the heatmap for grad-CAM\n",
    "    heatmap = grad_cam(input_tensor)\n",
    "    grad_cam.release()\n",
    "\n",
    "    # Ensure the heatmap is normalized\n",
    "    normalized_heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n",
    "\n",
    "    # Create an RGBA image for `dominant_image` where the alpha channel is adjusted according to the heatmap\n",
    "    dominant_rgba_image = np.zeros((*dominant_image.shape[:2], 4), dtype=np.float32) \n",
    "\n",
    "    for i in range(3):  # Copy the RGB channels\n",
    "        dominant_rgba_image[..., i] = dominant_image[..., i] / 255.0  # Normalize and copy\n",
    "    dominant_rgba_image[..., 3] = normalized_heatmap  # Adjust the alpha channel using the heatmap\n",
    "\n",
    "    # Plot image (sanity check)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.imshow(dominant_rgba_image)  # Show the RGBA image\n",
    "    ax.axis('on')  # Show the axes\n",
    "\n",
    "    # Define the color palette and labels for the `dominant_image` legend\n",
    "    color_map = {\n",
    "        \"Bare\": 'saddlebrown',\n",
    "        \"BuiltUp\": 'red',\n",
    "        \"Crops\": 'yellow',\n",
    "        \"Grass\": 'lightgreen',\n",
    "        \"MossLichen\": 'limegreen',\n",
    "        \"PermanentWater\": 'blue',\n",
    "        \"SeasonalWater\": 'cyan',\n",
    "        \"Shrub\": 'olive',\n",
    "        \"Tree\": 'darkgreen'\n",
    "    }\n",
    "    patches = [mpatches.Patch(color=to_rgb(color), label=label) for label, color in color_map.items()]\n",
    "\n",
    "    # Hide axis labels\n",
    "    ax.xaxis.set_ticks([])  # Hide x-axis labels and ticks\n",
    "    ax.yaxis.set_ticks([])  # Hide y-axis labels and ticks\n",
    "\n",
    "    # Add the legend for land cover\n",
    "    legend = ax.legend(handles=patches, loc='upper left', title=\"Land Cover Types\", bbox_to_anchor=(1.05, 1), borderaxespad=0.)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Assuming 'dominant_image' and 'heatmap' are defined\n",
    "    # Ensure the heatmap is normalized\n",
    "    normalized_heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n",
    "\n",
    "    # Create an RGBA image for `dominant_image` where the alpha channel is adjusted according to the heatmap\n",
    "    dominant_rgba_image = np.zeros((*dominant_image.shape[:2], 4), dtype=np.float32)  # Create RGBA image\n",
    "\n",
    "    for i in range(3):  # Copy the RGB channels\n",
    "        dominant_rgba_image[..., i] = np.around(dominant_image[..., i] / 255.0, 7)  # Normalize and copy\n",
    "\n",
    "    ########################################################\n",
    "    # Adjust the alpha channel using the heatmap with the threshold\n",
    "    threshold = 0.0\n",
    "    #######################################################\n",
    "\n",
    "    alpha_channel = np.where(normalized_heatmap > threshold, 1.0, 0)\n",
    "    dominant_rgba_image[..., 3] = alpha_channel  # Apply the modified alpha channel\n",
    "\n",
    "    # Create image\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.imshow(dominant_rgba_image)\n",
    "    ax.axis('on')\n",
    "\n",
    "    # Define the color palette and labels for the `dominant_image` legend\n",
    "    color_map = {\n",
    "        \"Bare\": 'saddlebrown',\n",
    "        \"BuiltUp\": 'red',\n",
    "        \"Crops\": 'yellow',\n",
    "        \"Grass\": 'lightgreen',\n",
    "        \"MossLichen\": 'limegreen',\n",
    "        \"PermanentWater\": 'blue',\n",
    "        \"SeasonalWater\": 'cyan',\n",
    "        \"Shrub\": 'olive',\n",
    "        \"Tree\": 'darkgreen'\n",
    "    }\n",
    "    patches = [mpatches.Patch(color=to_rgb(color), label=label) for label, color in color_map.items()]\n",
    "    ax.xaxis.set_ticks([]) \n",
    "    ax.yaxis.set_ticks([])\n",
    "\n",
    "    # Add the legend for land cover\n",
    "    legend = ax.legend(handles=patches, loc='upper left', title=\"Land Cover Types\", bbox_to_anchor=(1.05, 1), borderaxespad=0.)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Sanity check\n",
    "\n",
    "    # Assuming `dominant_rgba_image` is your original RGBA image\n",
    "    alpha_mask = dominant_rgba_image[..., 3] == 1\n",
    "\n",
    "    # Create an output image that will be a copy of the original image\n",
    "    output_image = np.zeros_like(dominant_rgba_image)\n",
    "\n",
    "    # Copy only the pixels where alpha is 1\n",
    "    output_image[alpha_mask] = dominant_rgba_image[alpha_mask]\n",
    "\n",
    "    # Visualize the resulting image, which will now highlight the pixels with alpha = 1\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(output_image)\n",
    "    plt.title(\"Pixels with Alpha = 1\")\n",
    "    plt.axis('on')\n",
    "    plt.show()\n",
    "\n",
    "    #############################################\n",
    "    # EXTRACT CLUSTERS\n",
    "    #############################################\n",
    "    \n",
    "    # Convert the RGB image (ignoring alpha) to a binary image where there are non-black pixels\n",
    "    binary_image = np.any(output_image[..., :3] > 0, axis=-1)  # True where there is color\n",
    "\n",
    "    # Apply connected component labeling on the binary image\n",
    "    labeled_image = measure.label(binary_image, connectivity=2)  # Diagonal connections included\n",
    "\n",
    "    # Ensure that output_image only contains RGB channels\n",
    "    if output_image.shape[-1] == 4:  # If it still includes the alpha channel\n",
    "        output_image = output_image[..., :3]  # Take only the first three channels (RGB)\n",
    "\n",
    "    try:\n",
    "        image_labeled = color.label2rgb(labeled_image, output_image, kind='overlay', bg_label=0)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(image_labeled)\n",
    "        plt.title(\"Connected components\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Error converting labels to RGB:\", e)\n",
    "\n",
    "    #############################################\n",
    "    # SAVE INFO AS A DATAFRAME\n",
    "    #############################################\n",
    "\n",
    "    # Prepare data for the DataFrame\n",
    "    data = {\n",
    "        'x': [],\n",
    "        'y': [],\n",
    "        'cluster_label': [],\n",
    "        'grad_cam_value': []\n",
    "    }\n",
    "\n",
    "    # Iterate over each pixel in the labeled image\n",
    "    for (x, y), label in np.ndenumerate(labeled_image):\n",
    "        data['x'].append(x)\n",
    "        data['y'].append(y)\n",
    "        data['cluster_label'].append(label)\n",
    "        # Extract the value from the tensor using .item() and add it to the DataFrame\n",
    "        data['grad_cam_value'].append(heatmap[x, y].item())\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df)\n",
    "\n",
    "    ##############################\n",
    "    # Extract pixel's land cover from dominant image\n",
    "\n",
    "    # Mapping of color names to RGB (example values, adjust as necessary)\n",
    "    rgb_color_map = {\n",
    "        'saddlebrown': [139, 69, 19],\n",
    "        'red': [255, 0, 0],\n",
    "        'yellow': [255, 255, 0],\n",
    "        'lightgreen': [144, 238, 144],\n",
    "        'limegreen': [50, 205, 50],\n",
    "        'blue': [0, 0, 255],\n",
    "        'cyan': [0, 255, 255],\n",
    "        'olive': [128, 128, 0],\n",
    "        'darkgreen': [0, 100, 0]\n",
    "    }\n",
    "\n",
    "    # Reverse the color_map to get a mapping from RGB to ID\n",
    "    rgb_to_id = {tuple(value): key for key, value in rgb_color_map.items()}\n",
    "\n",
    "    id_to_color = {\n",
    "        0: 'saddlebrown',   # Bare\n",
    "        1: 'red',           # BuiltUp\n",
    "        2: 'yellow',        # Crops\n",
    "        3: 'lightgreen',    # Grass\n",
    "        4: 'limegreen',     # MossLichen\n",
    "        5: 'blue',          # PermanentWater\n",
    "        6: 'cyan',          # SeasonalWater\n",
    "        7: 'olive',         # Shrub\n",
    "        8: 'darkgreen'      # Tree\n",
    "    }\n",
    "\n",
    "    def map_pixels_to_ids(image):\n",
    "        # Assign a default ID for unmapped pixels\n",
    "        id_image = np.full((image.shape[0], image.shape[1]), -1, dtype=int)\n",
    "\n",
    "        # Convert the image to a list of tuples for efficient lookup\n",
    "        flattened_image = [tuple(pixel) for pixel in image.reshape(-1, image.shape[2])]\n",
    "\n",
    "        # Map each pixel using the dictionary, with a default ID if not found\n",
    "        id_flat = [rgb_to_id.get(pixel, -1) for pixel in flattened_image]\n",
    "\n",
    "        # Reconstruct the ID image\n",
    "        id_image = np.array(id_flat).reshape(image.shape[0], image.shape[1])\n",
    "\n",
    "        return id_image\n",
    "\n",
    "    # Apply the function to the image\n",
    "    color_matrix = map_pixels_to_ids(dominant_image)\n",
    "\n",
    "    # Direct mapping from ID to color name\n",
    "    id_to_color = {\n",
    "        0: 'saddlebrown',   # Bare\n",
    "        1: 'red',           # BuiltUp\n",
    "        2: 'yellow',        # Crops\n",
    "        3: 'lightgreen',    # Grass\n",
    "        4: 'limegreen',     # MossLichen\n",
    "        5: 'blue',          # PermanentWater\n",
    "        6: 'cyan',          # SeasonalWater\n",
    "        7: 'olive',         # Shrub\n",
    "        8: 'darkgreen'      # Tree\n",
    "    }\n",
    "\n",
    "    # Labels for each ID\n",
    "    labels = {\n",
    "        0: \"Bare\",\n",
    "        1: \"Built-Up\",\n",
    "        2: \"Crops\",\n",
    "        3: \"Grass\",\n",
    "        4: \"Moss/Lichen\",\n",
    "        5: \"Permanent Water\",\n",
    "        6: \"Seasonal Water\",\n",
    "        7: \"Shrub\",\n",
    "        8: \"Tree\"\n",
    "    }\n",
    "\n",
    "    # Create a dictionary to map from color to land cover label\n",
    "    color_to_label = {color: labels[id] for id, color in id_to_color.items()}\n",
    "    # Convert color names to land cover labels\n",
    "    label_matrix = [[color_to_label.get(color, 'Unknown') for color in row] for row in color_matrix]\n",
    "\n",
    "    # Create a list to store the dictionaries\n",
    "    data_landcover = []\n",
    "\n",
    "    # Iterate over each row and each column in the matrix\n",
    "    for y, row in enumerate(label_matrix):\n",
    "        for x, label in enumerate(row):\n",
    "            # Create a dictionary for each cell and add it to the list\n",
    "            data_landcover.append({\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'land_cover': label,\n",
    "                'site': input_tensor_number\n",
    "            })\n",
    "\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    df_landcover = pd.DataFrame(data_landcover)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df_landcover)\n",
    "\n",
    "    # Assuming df and df_landcover are already defined as in your description\n",
    "    # Perform the left join\n",
    "    df_merged = pd.merge(df_landcover, df, on=['x', 'y'], how='left')\n",
    "\n",
    "    # Add the DataFrame to the total results DataFrame\n",
    "    result_df = pd.concat([result_df, df_merged], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a400bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the resulting DataFrame as a CSV file\n",
    "result_df.to_csv('../../Data/df_features_visualization.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1de28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
